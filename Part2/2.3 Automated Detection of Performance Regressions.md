有时候无法精确模拟“内部”性能测试的确切行为。这就是为什么越来越多的云服务提供商和超大规模计算者选择在生产系统上直接进行性能分析和监控 \[Ren等，2010\]。当不存在其他参与者时进行性能测量可能无法反映真实的场景。在实验室环境中实现良好但在生产环境中不适用的代码优化是浪费时间。尽管如此，这并不意味着不再需要进行持续的“内部”测试以及早发现性能问题。并非所有性能回归都能在实验室中捕捉到，但工程师应设计代表真实场景的性能基准。大型服务提供商实施在用户设备上监控性能的遥测系统正成为一种趋势。其中一个例子是Netflix的Icarus25遥测服务，它在遍布全球的数千台不同设备上运行。这样的遥测系统有助于Netflix了解真实用户对其应用性能的感知。它使工程师能够分析从许多设备收集的数据，并发现其他情况下难以发现的问题。这种数据能够做出更明智的决策，确定优化工作的重点。

监控生产部署的一个重要注意事项是测量开销。因为任何类型的监控都会影响运行服务的性能，建议只使用轻量级的分析方法。根据\[Ren等，2010\]的说法：“在为实际流量服务的数据中心机器上进行持续分析，非常低的开销至关重要”。通常，可接受的聚合开销应低于1%。通过限制分析的机器集合以及使用较小的时间间隔，可以降低性能监控的开销。

在这样的生产环境中进行性能测量意味着我们必须接受其嘈杂的特性，并使用统计方法来分析结果。LinkedIn等大型公司如何在生产环境的A/B测试中使用统计方法来衡量和比较基于分位数的指标（例如90th百分位的页面加载时间），可参考\[Liu等，2019\]。

### 2.3 自动检测性能回归

越来越多的软件供应商试图增加部署的频率。公司不断寻求加快产品交付到市场的速度的方法。然而，这并不意味着每个新版本的软件产品都会变得更好。特别是，软件性能缺陷往往以惊人的速度泄漏到生产软件中[Jin et al., 2012]。软件中的大量变更给分析所有这些结果和历史数据以检测性能回归带来了挑战。

软件性能回归是在软件从一个版本演变到下一个版本时错误地引入的缺陷。捕捉性能错误和改进意味着在测试基础设施的噪声存在下，检测到哪些提交改变了软件的性能（通过性能测试进行测量）。从数据库系统到搜索引擎到编译器，几乎所有大型软件系统在持续演进和部署生命周期中都会经历性能回归。在软件开发过程中完全避免性能回归可能是不可能的，但通过适当的测试和诊断工具，可以尽量减少这类缺陷悄然泄漏到生产代码的可能性。


[^25][在CMG 2019中介绍](https://www.youtube.com/watch?v=4RG2DUK03_0)

